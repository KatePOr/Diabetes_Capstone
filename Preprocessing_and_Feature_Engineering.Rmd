---
title: "Preprocessing and Feature Engineering"
author: "Kate O'Rourke"
date: "2024-11-14"
output: pdf_document
---
# General Preprocessing Steps for Feature Engineering

## Libraries
```{r}
library(dplyr)
library(caret) # used to split dataset
library(readr)
library(gtsummary)
```

## Read in dataset - KO
```{r}
CDC_2023_subset <- read_csv("CDC_2023_cleaned.csv")
```

## Remove unused columns - KO
```{r}
CDC_2023_subset <-  subset(CDC_2023_subset, select = -c(1, 5:6, 22, 24) )
```

## Convert columns (except for PHYSHLTH, MENTHLTH, DRNK3GE5, _AGE80, BMI) to factors - KO
```{r}
col_names <- colnames(CDC_2023_subset)
col_names <- col_names[-c(5:6, 10, 19, 20)] # Column 5 (PHYSHLTH), 6 (MENTHLTH), 10 (DRNK3GE5), 19 (_AGE80), 20 (BMI)
CDC_2023_subset[,col_names] <- lapply(CDC_2023_subset[,col_names] , factor)
```

### Get columns summaries for data - KO
```{r}
CDC_2023_subset %>%
  tbl_summary()
```

## Function to normalize BMI column - KO
```{r}
# Function to normalize specific columns based on dataset and columns specified
normalize <- function(dataset, columns) {
  dataset[, columns] <- scale(dataset[, columns],
                              center = apply(dataset[, columns], 2, mean),
                              scale = apply(dataset[, columns], 2, sd)
                              )
}
```

## Calculate test and training split - KO (function sourced from Katherine S. Geist)
```{r}
## Written by Katherine S. Geist, PhD
## Merrimack College, Massachusetts
## Please do not distribute without attribution
## https://github.com/ksgeist

calcSplitRatio <- function(p = NA, df) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target
  if(is.na(p)) {
    p <- ncol(df) -1   ## COMMENT HERE
  }
  
  ## Calculate the ideal number of testing set
  test_N <- (1/sqrt(p))*nrow(df)
  ## Turn that into a testing proportion
  test_prop <- round((1/sqrt(p))*nrow(df)/nrow(df), 2)
  ## And find the training proportion
  train_prop <- 1-test_prop
  
  ## Tell us the results!
  print(paste0("The ideal split ratio is ", train_prop, ":", test_prop, " training:testing"))
  
  ## Return the size of the training set
  return(train_prop)
}

calcSplitRatio(p=NA, CDC_2023_subset)
```
Dataset will be split into 77% training and 23% testing.

## Split dataset into training and test sets - KO
```{r}
training <- createDataPartition(CDC_2023_subset$DIABETE4,
                                         p = 0.77,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_subset[training, ]
CDC_2023_test <- CDC_2023_subset[-training, ]
```

## Normalize Numeric Columns in training and test sets - KO
```{r}
columns = c(5:6, 10, 19, 20)
normalize(CDC_2023_training, columns)
normalize(CDC_2023_test, columns)
```

## Check proportions of DIABETE4 in training and test sets - KO
```{r}
prop.table(table(CDC_2023_training$DIABETE4))
prop.table(table(CDC_2023_test$DIABETE4))
```

# Lasso Regression - SG

## Install and load the glmnet package
```{r}
library(glmnet)
```

## Prepare training and test datasets - SG
```{r}
CDC_2023_training <- CDC_2023_training[, colnames(CDC_2023_training) != "DIABTYPE"]

# Identify single-level factor columns in CDC_2023_test
single_level_factors_test <- sapply(CDC_2023_test, function(x) is.factor(x) && length(levels(x)) < 2)

CDC_2023_test <- CDC_2023_test[, colnames(CDC_2023_training) != "DIABTYPE"]

CDC_2023_test <- CDC_2023_test[, !single_level_factors_test]
```

## Remove the response variable (DIABETE4) from predictors - SG
```{r}
X_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training)[,-1]  # Exclude intercept
y_train <- CDC_2023_training$DIABETE4

X_test <- model.matrix(DIABETE4 ~ ., data = CDC_2023_test)[,-1]  # Exclude intercept
y_test <- CDC_2023_test$DIABETE4
```


## Perform Lasso regression with cross-validation - SG
```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")

# Find the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
plot(lasso_model)

# Fit the Lasso model with the best lambda
final_lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda, family = "binomial")

# Predict on the test set
predictions <- predict(final_lasso_model, s = best_lambda, newx = X_test, type = "response")

# Convert predictions to binary outcomes
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = predicted_classes, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy: ", accuracy, "\n")

# Print lasso coefficients
coef(final_lasso_model)
```

# Preprocessing and Feature Engineering for Social Factors Model

# Calculate test and training split for Social Factors Subset - KO (function sourced from Katherine S. Geist)
```{r}
# Subset data to only include Social Factors
CDC_2023_Social_Factors = subset(CDC_2023_subset, 
                         select = c(PHYSHLTH, MENTHLTH, PERSDOC3, MEDCOST1, 
                                    SMOKE100, DRNK3GE5, EXERANY2, DIABETE4)
                         )

## Written by Katherine S. Geist, PhD
## Merrimack College, Massachusetts
## Please do not distribute without attribution
## https://github.com/ksgeist

calcSplitRatio <- function(p = NA, df) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target
  if(is.na(p)) {
    p <- ncol(df) -1   ## COMMENT HERE
  }
  
  ## Calculate the ideal number of testing set
  test_N <- (1/sqrt(p))*nrow(df)
  ## Turn that into a testing proportion
  test_prop <- round((1/sqrt(p))*nrow(df)/nrow(df), 2)
  ## And find the training proportion
  train_prop <- 1-test_prop
  
  ## Tell us the results!
  print(paste0("The ideal split ratio is ", train_prop, ":", test_prop, " training:testing"))
  
  ## Return the size of the training set
  return(train_prop)
}

calcSplitRatio(p=NA, CDC_2023_Social_Factors)
```

## Split dataset into training and test sets - KO
```{r}
training <- createDataPartition(CDC_2023_Social_Factors$DIABETE4,
                                         p = 0.62,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_Social_Factors[training, ]
CDC_2023_test <- CDC_2023_Social_Factors[-training, ]
```

## Normalize Numeric Columns in training and test sets - KO
```{r}
columns = c(1:2, 6)
normalize(CDC_2023_training, columns)
normalize(CDC_2023_test, columns)
```

## Check proportions of DIABETE4 in training and test sets - KO
```{r}
prop.table(table(CDC_2023_training$DIABETE4))
prop.table(table(CDC_2023_test$DIABETE4))
```

# Lasso Regression - SG

## Install and load the glmnet package
```{r}
library(glmnet)
```

## Prepare training and test datasets - SG
```{r}
CDC_2023_training <- CDC_2023_training[, colnames(CDC_2023_training) != "DIABTYPE"]

# Identify single-level factor columns in CDC_2023_test
single_level_factors_test <- sapply(CDC_2023_test, function(x) is.factor(x) && length(levels(x)) < 2)

CDC_2023_test <- CDC_2023_test[, colnames(CDC_2023_training) != "DIABTYPE"]

CDC_2023_test <- CDC_2023_test[, !single_level_factors_test]
```

## Remove the response variable (DIABETE4) from predictors - SG
```{r}
X_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training)[,-1]  # Exclude intercept
y_train <- CDC_2023_training$DIABETE4

X_test <- model.matrix(DIABETE4 ~ ., data = CDC_2023_test)[,-1]  # Exclude intercept
y_test <- CDC_2023_test$DIABETE4
```


## Perform Lasso regression with cross-validation - SG
```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")

# Find the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
plot(lasso_model)

# Fit the Lasso model with the best lambda
final_lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda, family = "binomial")

# Predict on the test set
predictions <- predict(final_lasso_model, s = best_lambda, newx = X_test, type = "response")

# Convert predictions to binary outcomes
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = predicted_classes, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy: ", accuracy, "\n")

# Print lasso coefficients
coef(final_lasso_model)
```

# Preprocessing and Feature Engineering for Demographics Model

# Calculate test and training split for Demographics Subset - KO (function sourced from Katherine S. Geist)
```{r}
# Subset data to only include Demographics
CDC_2023_Demographics = subset(CDC_2023_subset, 
                         select = c(EDUCA, EMPLOY1, INCOME3, SEXVAR, BMI, `_AGE80`, DIABETE4)
                         )

## Written by Katherine S. Geist, PhD
## Merrimack College, Massachusetts
## Please do not distribute without attribution
## https://github.com/ksgeist

calcSplitRatio <- function(p = NA, df) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target
  if(is.na(p)) {
    p <- ncol(df) -1   ## COMMENT HERE
  }
  
  ## Calculate the ideal number of testing set
  test_N <- (1/sqrt(p))*nrow(df)
  ## Turn that into a testing proportion
  test_prop <- round((1/sqrt(p))*nrow(df)/nrow(df), 2)
  ## And find the training proportion
  train_prop <- 1-test_prop
  
  ## Tell us the results!
  print(paste0("The ideal split ratio is ", train_prop, ":", test_prop, " training:testing"))
  
  ## Return the size of the training set
  return(train_prop)
}

calcSplitRatio(p=NA, CDC_2023_Demographics)
```

## Split dataset into training and test sets - KO
```{r}
training <- createDataPartition(CDC_2023_Demographics$DIABETE4,
                                         p = 0.59,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_Demographics[training, ]
CDC_2023_test <- CDC_2023_Demographics[-training, ]
```

## Normalize Numeric Columns in training and test sets - KO
```{r}
columns = c(5:6)
normalize(CDC_2023_training, columns)
normalize(CDC_2023_test, columns)
```

## Check proportions of DIABETE4 in training and test sets - KO
```{r}
prop.table(table(CDC_2023_training$DIABETE4))
prop.table(table(CDC_2023_test$DIABETE4))
```

# Lasso Regression - SG

## Prepare training and test datasets - SG
```{r}
CDC_2023_training <- CDC_2023_training[, colnames(CDC_2023_training) != "DIABTYPE"]

# Identify single-level factor columns in CDC_2023_test
single_level_factors_test <- sapply(CDC_2023_test, function(x) is.factor(x) && length(levels(x)) < 2)

CDC_2023_test <- CDC_2023_test[, colnames(CDC_2023_training) != "DIABTYPE"]

CDC_2023_test <- CDC_2023_test[, !single_level_factors_test]
```

## Remove the response variable (DIABETE4) from predictors - SG
```{r}
X_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training)[,-1]  # Exclude intercept
y_train <- CDC_2023_training$DIABETE4

X_test <- model.matrix(DIABETE4 ~ ., data = CDC_2023_test)[,-1]  # Exclude intercept
y_test <- CDC_2023_test$DIABETE4
```


## Perform Lasso regression with cross-validation - SG
```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")

# Find the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
plot(lasso_model)

# Fit the Lasso model with the best lambda
final_lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda, family = "binomial")

# Predict on the test set
predictions <- predict(final_lasso_model, s = best_lambda, newx = X_test, type = "response")

# Convert predictions to binary outcomes
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = predicted_classes, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy: ", accuracy, "\n")

# Print lasso coefficients
coef(final_lasso_model)
```

# Preprocessing and Feature Engineering for Diseases Model

# Calculate test and training split for Disease Subset - KO (function sourced from Katherine S. Geist)
```{r}
# Subset data to only include Diseases
CDC_2023_Disease = subset(CDC_2023_subset, 
                         select = c(BPHIGH6, TOLDHI3, CVDINFR4, CVDCRHD4, CVDSTRK3, CHCKDNY2, DIABETE4)
                         )

## Written by Katherine S. Geist, PhD
## Merrimack College, Massachusetts
## Please do not distribute without attribution
## https://github.com/ksgeist

calcSplitRatio <- function(p = NA, df) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target
  if(is.na(p)) {
    p <- ncol(df) -1   ## COMMENT HERE
  }
  
  ## Calculate the ideal number of testing set
  test_N <- (1/sqrt(p))*nrow(df)
  ## Turn that into a testing proportion
  test_prop <- round((1/sqrt(p))*nrow(df)/nrow(df), 2)
  ## And find the training proportion
  train_prop <- 1-test_prop
  
  ## Tell us the results!
  print(paste0("The ideal split ratio is ", train_prop, ":", test_prop, " training:testing"))
  
  ## Return the size of the training set
  return(train_prop)
}

calcSplitRatio(p=NA, CDC_2023_Disease)
```

## Split dataset into training and test sets - KO
```{r}
training <- createDataPartition(CDC_2023_Disease$DIABETE4,
                                         p = 0.59,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_Disease[training, ]
CDC_2023_test <- CDC_2023_Disease[-training, ]
```

## Check proportions of DIABETE4 in training and test sets - KO
```{r}
prop.table(table(CDC_2023_training$DIABETE4))
prop.table(table(CDC_2023_test$DIABETE4))
```

# Lasso Regression - SG

## Prepare training and test datasets - SG
```{r}
CDC_2023_training <- CDC_2023_training[, colnames(CDC_2023_training) != "DIABTYPE"]

# Identify single-level factor columns in CDC_2023_test
single_level_factors_test <- sapply(CDC_2023_test, function(x) is.factor(x) && length(levels(x)) < 2)

CDC_2023_test <- CDC_2023_test[, colnames(CDC_2023_training) != "DIABTYPE"]

CDC_2023_test <- CDC_2023_test[, !single_level_factors_test]
```

## Remove the response variable (DIABETE4) from predictors - SG
```{r}
X_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training)[,-1]  # Exclude intercept
y_train <- CDC_2023_training$DIABETE4

X_test <- model.matrix(DIABETE4 ~ ., data = CDC_2023_test)[,-1]  # Exclude intercept
y_test <- CDC_2023_test$DIABETE4
```


## Perform Lasso regression with cross-validation - SG
```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")

# Find the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
plot(lasso_model)

# Fit the Lasso model with the best lambda
final_lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda, family = "binomial")

# Predict on the test set
predictions <- predict(final_lasso_model, s = best_lambda, newx = X_test, type = "response")

# Convert predictions to binary outcomes
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = predicted_classes, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy: ", accuracy, "\n")

# Print lasso coefficients
coef(final_lasso_model)
```
## Lasso Regression Including All Predictor Variables - SG
```{r}
# Extract coefficients at the best lambda
coefficients <- coef(lasso_model, s = best_lambda)
coefficients_df <- as.data.frame(as.matrix(coefficients))
colnames(coefficients_df) <- "Coefficient"
coefficients_df$Variable <- rownames(coefficients_df)
rownames(coefficients_df) <- NULL

# Print the table
print(coefficients_df)

```

## Lasso Regression Including Social Factors Predictor Variables - SG
```{r}
# Subset predictors for social factors
social_factors <- c("PHYSHLTH", "MENTHLTH", "PERSDOC3", "MEDCOST1", 
                    "SMOKE100", "DRNK3GE5", "EXERANY2")

X_social_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training[, c(social_factors, "DIABETE4")])[,-1]
y_social_train <- as.numeric(CDC_2023_training$DIABETE4)

# Fit Lasso Regression with social factors only
lasso_social_model <- cv.glmnet(X_social_train, y_social_train, alpha = 1, family = "binomial")

# Extract best lambda
best_lambda_social <- lasso_social_model$lambda.min
print(best_lambda_social)

# Extract coefficients at best lambda
social_coefficients <- coef(lasso_social_model, s = best_lambda_social)
social_coefficients_df <- as.data.frame(as.matrix(social_coefficients))
colnames(social_coefficients_df) <- "Coefficient"
social_coefficients_df$Variable <- rownames(social_coefficients_df)
rownames(social_coefficients_df) <- NULL

# Print the table
print(social_coefficients_df)

```

## Lasso Regression Including Demographic Predictor Variables - SG
```{r}
# Subset predictors for demographic factors
demographic_factors <- c("EDUCA", "EMPLOY1", "INCOME3", "SEXVAR", "_AGE80", "BMI")

X_demo_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training[, c(demographic_factors, "DIABETE4")])[,-1]
y_demo_train <- as.numeric(CDC_2023_training$DIABETE4)

# Fit Lasso Regression with demographic factors only
lasso_demo_model <- cv.glmnet(X_demo_train, y_demo_train, alpha = 1, family = "binomial")

# Extract best lambda
best_lambda_demo <- lasso_demo_model$lambda.min
print(best_lambda_demo)

# Extract coefficients at best lambda
demo_coefficients <- coef(lasso_demo_model, s = best_lambda_demo)
demo_coefficients_df <- as.data.frame(as.matrix(demo_coefficients))
colnames(demo_coefficients_df) <- "Coefficient"
demo_coefficients_df$Variable <- rownames(demo_coefficients_df)
rownames(demo_coefficients_df) <- NULL

# Print the table
print(demo_coefficients_df)

```

## Lasso Regression Including Disease Predictor Variables - SG
```{r}
# Subset predictors for disease factors
disease_factors <- c("BPHIGH6", "TOLDHI3", "CVDINFR4", "CVDCRHD4", "CVDSTRK3", "CHCKDNY2")

# Create model matrix for training data (exclude intercept column)
X_disease_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training[, c(disease_factors, "DIABETE4")])[,-1]

# Response variable
y_disease_train <- as.numeric(CDC_2023_training$DIABETE4)

# Fit Lasso Regression with disease-related factors
lasso_disease_model <- cv.glmnet(X_disease_train, y_disease_train, alpha = 1, family = "binomial")

# Extract best lambda
best_lambda_disease <- lasso_disease_model$lambda.min
print(best_lambda_disease)

# Extract coefficients at best lambda
disease_coefficients <- coef(lasso_disease_model, s = best_lambda_disease)
disease_coefficients_df <- as.data.frame(as.matrix(disease_coefficients))
colnames(disease_coefficients_df) <- "Coefficient"
disease_coefficients_df$Variable <- rownames(disease_coefficients_df)
rownames(disease_coefficients_df) <- NULL

# Print the table
print(disease_coefficients_df)
```
