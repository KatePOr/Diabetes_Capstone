---
title: "Preprocessing and Feature Engineering"
author: "Kate O'Rourke"
date: "2024-11-14"
output: pdf_document
---
# General Preprocessing Steps for Feature Engineering

## Libraries
```{r}
library(dplyr)
library(caret) # used to split dataset
library(readr)
library(gtsummary)
library(ggplot2)
library(glmnet)
```

## Read in dataset - KO
```{r}
CDC_2023_subset <- read_csv("CDC_2023_cleaned.csv")
```

## Remove unused columns - KO
```{r}
CDC_2023_subset <-  subset(CDC_2023_subset, select = -c(1, 5:6, 22, 24) )
```

## Convert columns (except for EDUCA, EMPLOY1, INCOME3, PHYSHLTH, MENTHLTH, DRNK3GE5, _AGE80, BMI) to factors - KO
```{r}
col_names <- colnames(CDC_2023_subset)
col_names <- col_names[-c(1:3, 5:6, 10, 19, 20)] # Column 1 (EDUCA), 2 (EMPLOY1), 3 (INCOME3), 5 (PHYSHLTH), 6 (MENTHLTH), 10 (DRNK3GE5), 19 (_AGE80), 20 (BMI)
CDC_2023_subset[,col_names] <- lapply(CDC_2023_subset[,col_names] , factor)
```

### Get columns summaries for data - KO
```{r}
CDC_2023_subset %>%
  tbl_summary()
```

## Function to normalize columns - KO
```{r}
# Function to normalize specific columns based on dataset and columns specified
normalize <- function(dataset, columns) {
  scale(dataset[, columns],
  center = apply(dataset[, columns], 2, mean),
  scale = apply(dataset[, columns], 2, sd)
  )
}
```

## Calculate test and training split - KO (function sourced from Katherine S. Geist)
```{r}
## Written by Katherine S. Geist, PhD
## Merrimack College, Massachusetts
## Please do not distribute without attribution
## https://github.com/ksgeist

calcSplitRatio <- function(p = NA, df) {
  ## @p  = the number of parameters. by default, if none are provided, the number of columns (predictors) in the dataset are used
  ## @df = the dataframe that will be used for the analysis
  
  ## If the number of parameters isn't supplied, set it to the number of features minus 1 for the target
  if(is.na(p)) {
    p <- ncol(df) -1   ## COMMENT HERE
  }
  
  ## Calculate the ideal number of testing set
  test_N <- (1/sqrt(p))*nrow(df)
  ## Turn that into a testing proportion
  test_prop <- round((1/sqrt(p))*nrow(df)/nrow(df), 2)
  ## And find the training proportion
  train_prop <- 1-test_prop
  
  ## Tell us the results!
  print(paste0("The ideal split ratio is ", train_prop, ":", test_prop, " training:testing"))
  
  ## Return the size of the training set
  return(train_prop)
}

calcSplitRatio(p=NA, CDC_2023_subset)
```
Dataset will be split into 77% training and 23% testing.

## Split dataset into training and test sets - KO
```{r}
set.seed(100)
training <- createDataPartition(CDC_2023_subset$DIABETE4,
                                         p = 0.77,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_subset[training, ]
CDC_2023_test <- CDC_2023_subset[-training, ]
```

## Normalize Numeric and ordinal Columns in training and test sets - KO
```{r}
columns = c(1:3, 5:6, 10, 19, 20)
CDC_2023_training[, columns] <- normalize(CDC_2023_training, columns)
CDC_2023_test[, columns] <- normalize(CDC_2023_test, columns)
```

## Check proportions of DIABETE4 in training and test sets - KO
```{r}
prop.table(table(CDC_2023_training$DIABETE4))
prop.table(table(CDC_2023_test$DIABETE4))
```

# Lasso Regression - SG

## Prepare training and test datasets - SG
```{r}
CDC_2023_training <- CDC_2023_training[, colnames(CDC_2023_training) != "DIABTYPE"]

# Identify single-level factor columns in CDC_2023_test
single_level_factors_test <- sapply(CDC_2023_test, function(x) is.factor(x) && length(levels(x)) < 2)

CDC_2023_test <- CDC_2023_test[, colnames(CDC_2023_training) != "DIABTYPE"]

CDC_2023_test <- CDC_2023_test[, !single_level_factors_test]
```

## Remove the response variable (DIABETE4) from predictors - SG
```{r}
X_train <- model.matrix(DIABETE4 ~ ., data = CDC_2023_training)[,-1]  # Exclude intercept
y_train <- CDC_2023_training$DIABETE4

X_test <- model.matrix(DIABETE4 ~ ., data = CDC_2023_test)[,-1]  # Exclude intercept
y_test <- CDC_2023_test$DIABETE4
```


## Perform Lasso regression with cross-validation - SG
```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")

# Find the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
plot(lasso_model)

# Fit the Lasso model with the best lambda
final_lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda, family = "binomial")

# Predict on the test set
predictions <- predict(final_lasso_model, s = best_lambda, newx = X_test, type = "response")

# Convert predictions to binary outcomes
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = predicted_classes, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy: ", accuracy, "\n")

# Print lasso coefficients
coef(final_lasso_model)
```