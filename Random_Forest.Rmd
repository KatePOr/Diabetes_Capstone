---
title: "Random Forest All Variables Model"
author: "Kate O'Rourke"
date: "2024-11-21"
output: pdf_document
---

## Libraries
```{r}
library(dplyr)
library(caret) # used to split dataset
library(readr)
library(ggplot2)
library(pROC)
library(tidymodels) 
library(randomForest) # For tuning model
library(reshape2)
library(car)
library(yardstick)
library(ranger)
library(themis)
library(plot3D)
library(vip)
```

## Set seed
```{r}
set.seed(123)
```

# Preprocessing

## Read in dataset - KO
```{r}
CDC_2023_subset <- read_csv("CDC_2023_cleaned.csv")
```

## Remove unused columns - KO
```{r}
CDC_2023_subset <-  subset(CDC_2023_subset, select = -c(1, 5:6, 22, 24) )
```

## Convert columns (except for EDUCA, EMPLOY1, INCOME3, PHYSHLTH, MENTHLTH, DRNK3GE5, _AGE80, BMI) to factors - KO
```{r}
col_names <- colnames(CDC_2023_subset)
col_names <- col_names[-c(1:3, 5:6, 10, 19, 20)] # Column 1 (EDUCA), 2 (EMPLOY1), 3 (INCOME3), 5 (PHYSHLTH), 6 (MENTHLTH), 10 (DRNK3GE5), 19 (_AGE80), 20 (BMI)
CDC_2023_subset[,col_names] <- lapply(CDC_2023_subset[,col_names] , factor)
```

## Function to normalize numeric columns - KO
```{r}
# Function to normalize specific columns based on dataset and columns specified
normalize <- function(dataset, columns) {
  scale(dataset[, columns],
  center = apply(dataset[, columns], 2, mean),
  scale = apply(dataset[, columns], 2, sd)
  )
}
```

## Split dataset into training and test sets - KO
Dataset will be split into 77% training and 23% testing.
```{r}
training <- createDataPartition(CDC_2023_subset$DIABETE4,
                                         p = 0.77,
                                         list = FALSE,
                                         times = 1)

CDC_2023_training <- CDC_2023_subset[training, ]
CDC_2023_test <- CDC_2023_subset[-training, ]
```

## Normalize Numeric Columns in training and test sets - KO
```{r}
columns = c(1:3, 5:6, 10, 19, 20)
CDC_2023_training[, columns] <- normalize(CDC_2023_training, columns)
CDC_2023_test[, columns] <- normalize(CDC_2023_test, columns)
```

## Change _AGE80 column name to avoid potential errors - KO
```{r}
CDC_2023_training <- CDC_2023_training %>%
  rename( AGE80 = `_AGE80` )

CDC_2023_test <- CDC_2023_test %>%
  rename( AGE80 = `_AGE80` )
```


# K-Fold Stratified Grid Cross-Validation
# Random Forest Coss-Validation - KO + SG

```{r}
# Define resampling method using 5-fold cross-validation
set.seed(123)  # For reproducibility

# Calculate Weights for rf_pred
CDC_2023_training <-
  CDC_2023_training %>% 
  mutate(
    case_wts = ifelse(DIABETE4 == "1", 18, 1),
    case_wts = importance_weights(case_wts)
  )

# Define the recipe for pre-processing
diabetes_recipe <- 
  recipe(DIABETE4 ~ ., data = CDC_2023_training) %>%
  step_dummy(all_nominal_predictors())  # Handle categorical variables 
  

# Prep the recipe
diabetes_recipe_prepped <- prep(diabetes_recipe)

# Juice diabetes recipe
diabetes_recipe_juiced <- diabetes_recipe_prepped %>%
  juice()

# Define the Random Forest model specification
model_tune <- 
  rand_forest(
    mtry = tune(),
    min_n = tune(),
    trees = 50, 
    ) %>%
  set_engine("ranger", seed(123)) %>%
  set_mode("classification")

# 5-fold Stratified Cross-validation
cv_folds <- vfold_cv(diabetes_recipe_juiced, v = 5, strata = DIABETE4)

# Define the workflow
tune_rf <- workflow() %>%
  add_model(model_tune) %>%
  add_formula(DIABETE4~.) %>% #Should this be add recipe instead?? Test (prev. code: add_formula(DIABETE4~.) )
  add_case_weights(case_wts)

# According to preliminary tuning, optimal grid values are around mtry 2 and min_n
tuned <- tune_rf %>% 
  tune_grid(resamples = cv_folds, 
            grid =expand.grid(mtry=1:19, min_n=10:30),
            metrics = metric_set(yardstick::roc_auc))

df <- tuned %>% collect_metrics()
df <- df %>% arrange(-mean) %>% tibble(rank=seq_len(nrow(df)), .)
df

scatter3D(x=df$mtry, y=df$min_n, z=df$mean, phi = 0, bty = "g",  type = "h", 
          ticktype = "detailed", pch = 19, cex = 0.5, 
          main="the true distribution", xlab="mtry",
          ylab="min_n", zlab="roc_auc")
```

# Fit final model - KO
```{r}
set.seed(123)  # For reproducibility

# Random forest model with mtry and min_n set to best values from cross-validation
rf_spec <- 
  rand_forest( mode = "classification", 
               trees = 500, 
               mtry = 15,
               min_n = 10) %>%              
  set_engine("ranger", importance = "impurity")

# Define the workflow
rf_workflow <- 
  workflow() %>%
  add_recipe(diabetes_recipe) %>%
  add_model(rf_spec) %>%
  add_case_weights(case_wts)

# Train the final Random Forest model on the entire training data
final_rf_model <- rf_workflow %>%
  fit(data = CDC_2023_training)

# Bake the test dataset
test_baked <- bake(diabetes_recipe_prepped, new_data = CDC_2023_test)

# Generate predictions on the baked test data
test_results <- 
  test_baked %>%
  bind_cols(
    predict(final_rf_model, new_data = CDC_2023_test, type = "prob") %>%
      dplyr::rename(p_1 = .pred_1)  # Rename predicted probabilities
    ) %>%
  dplyr::mutate(DIABETE4 = CDC_2023_test$DIABETE4)  # Add true labels for evaluation

################################### feature importance ###################################

final_rf_model %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)

################################### plot ROC curve ###################################

roc_data <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data$threshold) {
  
  over_threshold <- test_results[test_results$p_1 >= i, ]
  
  fpr <- sum(over_threshold$DIABETE4==0)/sum(test_results$DIABETE4==0)
  roc_data[roc_data$threshold==i, "fpr"] <- fpr
  
  tpr <- sum(over_threshold$DIABETE4==1)/sum(test_results$DIABETE4==1)
  roc_data[roc_data$threshold==i, "tpr"] <- tpr
  
}

ggplot() +
  geom_line(data = roc_data, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
  scale_color_gradientn(colors = rainbow(3)) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(data = roc_data[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
  geom_text(data = roc_data[seq(1, 101, 10), ],
            aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
  theme_bw() +
  xlab("FPR") + 
  ylab("TPR")

############################# ROC curve calculation breakdown ############################

threshold <- 0.5

test_results$predictions <- ifelse(test_results$p_1 >= threshold, 1, 0)
tp <- nrow(test_results[test_results$DIABETE4==1 & test_results$predictions==1, ])
paste("True Positive:", tp)
fp <- nrow(test_results[test_results$DIABETE4==0 & test_results$predictions==1, ])
paste("False Positive:", fp)
tn <- nrow(test_results[test_results$DIABETE4==0 & test_results$predictions==0, ])
paste("True Negative:", tn)
fn <- nrow(test_results[test_results$DIABETE4==1 & test_results$predictions==0, ])
paste("False Negative:", fn)

test_results$type <- ""
test_results[test_results$DIABETE4==1 & test_results$predictions==1, "type"] <- "tp"
test_results[test_results$DIABETE4==0 & test_results$predictions==1, "type"] <- "fp"
test_results[test_results$DIABETE4==0 & test_results$predictions==0, "type"] <- "tn"
test_results[test_results$DIABETE4==1 & test_results$predictions==0, "type"] <- "fn"

fpr <- fp/(fp + tn)
tpr <- tp/(tp + fn)

acc <- (tp + tn) / (tp + tn + fp + fn)
paste("Accuracy: ", acc)

###################################          AUC           ###################################

roc_object <- roc( CDC_2023_test$DIABETE4, test_results$p_1)
auc(roc_object)

################################### plot calibration curve ###################################

calibration_data <- data.frame(bin_midpoint=seq(0.05,0.95,0.1),
                               observed_event_percentage=0)
for (i in seq(0.05,0.95,0.1)) {
  
  in_interval <- test_results[test_results$p_1 >= (i-0.05) & test_results$p_1 <= (i+0.05), ]
  oep <- nrow(in_interval[in_interval$DIABETE4==1, ])/nrow(in_interval)
  calibration_data[calibration_data$bin_midpoint==i, "observed_event_percentage"] <- oep
  
}

ggplot(data = calibration_data, aes(x = bin_midpoint, y = observed_event_percentage)) +
  geom_line(linewidth = 1) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(size = 2) +
  geom_text(aes(label = bin_midpoint), hjust = 0.75, vjust = -0.5) +
  xlab("Bin Midpoint") +
  ylab("Observed Event Percentage") + 
  theme_bw()

# Evaluate ROC-AUC on the test set
roc_object <- roc(test_results$DIABETE4, test_results$p_1)
auc_value <- auc(roc_object)
cat("Test ROC-AUC:", auc_value, "\n")
```